{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'temp_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3436c995eb0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m def runNN(train_features, train_label, test_features, test_label, n_neurons, n_epochs, seed=155,\n\u001b[0;32m----> 2\u001b[0;31m           \u001b[0mdata_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimesteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m52\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m           history=True, del_files=True, early_stopping=None):\n\u001b[1;32m      4\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#create model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'temp_data' is not defined"
     ]
    }
   ],
   "source": [
    "def runNN(train_features, train_label, test_features, test_label, n_neurons, n_epochs, seed=155,\n",
    "          data_dim = 13, timesteps = 1, batch_size = 52, states = temp_data.keys(),\n",
    "          history=True, del_files=True, early_stopping=None):\n",
    "    np.random.seed(seed)\n",
    "    #create model\n",
    "    rnn_model = simple_rnn_model(data_dim,timesteps,batch_size,states, n_neurons)\n",
    "    model_callbacks = []\n",
    "    if early_stopping is not None:\n",
    "        model_callbacks = [early_stopping]\n",
    "    if history:\n",
    "        processed_dir = os.path.join(os.getcwd(),os.pardir, 'models/')\n",
    "        filepath= processed_dir + \"nn_weights_%dneurons-{epoch:02d}.hdf5\" %n_neurons\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_weights_only=True,\n",
    "                                     save_best_only=False, mode='max')\n",
    "        model_callbacks.append(checkpoint)\n",
    "        print(\"model checkpoint\")\n",
    "        output = rnn_model.fit(train_features,\n",
    "                               train_label[0], #label for the targeted state\n",
    "                               validation_data= (\n",
    "                                   test_features,\n",
    "                                   test_label[0]),\n",
    "                               epochs=n_epochs, \n",
    "                               verbose=0, \n",
    "                               batch_size=batch_size,\n",
    "                               callbacks=model_callbacks, \n",
    "                               initial_epoch=0).history\n",
    "        \n",
    "        print(\"print loss\")\n",
    "    \n",
    "        time.sleep(1) # hack so that files can be opened in subsequent code\n",
    "        #create model\n",
    "        temp_val_model = simple_rnn_model(data_dim,timesteps,batch_size,states, n_neurons)\n",
    "        test_over_time = []\n",
    "        \n",
    "        for i in range(len(output['loss'])):\n",
    "            temp_val_model.load_weights(processed_dir + \"nn_weights_%dneurons-%02d.hdf5\" % (n_neurons,i))\n",
    "            scores = temp_val_model.evaluate(X_test_set, Y_test_set, verbose=0)\n",
    "            test_over_time.append(scores)\n",
    "            # delete files once we're done with them\n",
    "            if del_files:\n",
    "                os.remove(processed_dir + \"nn_weights_%dneurons-%02d.hdf5\" % (n_neurons,i))\n",
    "        \n",
    "        test_over_time = np.array(test_over_time)\n",
    "        output['test_loss'] = [row[0] for row in test_over_time]\n",
    "        output['test_acc'] = [row[1] for row in test_over_time]\n",
    "    else:\n",
    "        model_output = rnn_model.fit(train_features,\n",
    "                               train_label[0], #label for the targeted state\n",
    "                               validation_data= (\n",
    "                                   test_features,\n",
    "                                   test_label[0]),\n",
    "                               epochs=n_epochs, \n",
    "                               verbose=0, \n",
    "                               batch_size=batch_size,\n",
    "                               callbacks=model_callbacks, \n",
    "                               initial_epoch=0).history\n",
    "        validation_size = 0\n",
    "        output = {}\n",
    "        training_size = train_features[0].shape[0] - validation_size\n",
    "        train_scores = rnn_model.evaluate(train_features, train_label[0], verbose=0)\n",
    "        test_scores = rnn_model.evaluate(test_features, test_label[0], verbose=0)\n",
    "        output['train_loss'] = train_scores[0]\n",
    "        output['train_acc'] = train_scores[1]\n",
    "        output['test_loss'] = test_scores[0]\n",
    "        output['test_acc'] = test_scores[1]\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_second_nn = runNN(train_features, train_label, test_features, test_label, 50, 100)\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "ax1.plot(range(len(my_second_nn['loss'])),my_second_nn['loss'], color='blue',label='Training Set', lw=1.5)\n",
    "ax1.plot(range(len(my_second_nn['test_loss'])),my_second_nn['test_loss'], color='green',label='Test Set', lw=1.5)\n",
    "ax2.plot(range(len(my_second_nn['acc'])),my_second_nn['acc'], color='blue',label='Training Set', lw=1.5)\n",
    "ax2.plot(range(len(my_second_nn['test_acc'])),my_second_nn['test_acc'], color='green',label='Test Set', lw=1.5)\n",
    "leg = ax1.legend(bbox_to_anchor=(0.7, 0.9), loc=2, borderaxespad=0.,fontsize=13)\n",
    "ax1.set_xticklabels('')\n",
    "ax2.set_xlabel('# Epochs',fontsize=14)\n",
    "ax1.set_ylabel('Loss',fontsize=14)\n",
    "ax2.set_ylabel('Accuracy',fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "end = time.time()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
